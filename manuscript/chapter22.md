# Chapter 22

![The Test-Driven Analysis Wheel of Pain[^22-2]](images/Test-Driven-Analysis-Constellation.png)

[^22-2]: I jokingly call this the "Wheel of Pain" because it was painful to come up with, I imagine it will be used in all sorts of inappropriate and painful ways to make people's lives more painful, and once you narrow in on exactly what the hell you're doing, the types of questions themselves tend to be painful, at least the important ones.

You would think that in a book like this, at some point there would be a diagram of things you haven't seen before, maybe some kind of circle or loop. Some cool new process. Something you can show the other nerds down at the water cooler.

Process books love circles and loops, especially colored circles with little stick figures.

I don't want to disappoint you guys, but we did not have the budget for colored circles. Instead, all we could afford were a few dots. Even then, all we could get was grey.[^22:2]

[^22:2]: Sadly, we blew the budget on colored pyramids back in section one.

We've generalized conversations in this book, explaining how good conversations happen and why you can't replace conversations with data feeds. We've shown how to capture and store the minimum amount of information that  "remembers" what's important to you and reminds you of where and how good conversations can take place.

We've walked though a bunch of different scenarios, and as we finish out small team activities and move later to large teams, team-of-teams, programs, and the Meta genre -- we're found ourselves talking more and more about *action*, not information. Process. Meetings. That's because in order for you to learn important things about information (Structured Analysis), I have to walk you through a lot of action that generates and uses information, even if it's just pretend action.

What can we apply? What's best? What do all processes have in common? What's the best process for me? I'm looking at an A-7 scenario in this Nakatomi Tower project, dang it. Where's the little chart where I can take the A-7 scenario I have and cross-check it to find the step-by-step best process?

-sigh-

## Test-Driven Analysis Wheel

You'd think that if I were looking at trying to make some kind of generalizations about process, the obvious way would be to look at multiple examples of good processes and find similarities, right? Group them together. Look for commonalities.

Actually no. It doesn't work that way. At all.

The reason why is interesting in itself. Analysis is mostly mental, unspoken, and subconscious. The only thing I could do by cutting across and making inventories is gather together a bunch of stuff that various people have put together to do stuff -- all physical stuff, of course -- most of which relies on all of that hidden, undiscovered stuff to work in one form or another behind-the-scenes. It would be more like a survey than a generalization. And then most likely I'd end up with some version the measure-act-inspect loop, or DMAIC, or OODA. (All of which are wonderful loops. Big fan of OODA myself.)

This is why just about any process book has a circle or cycle in it. Once you see a cycle, it's impossible to un-see it. They're everywhere! They're everywhere! So we're all stuck in cycle-land whether that the best way of looking at things or not.

The actual way that seems to work is to scan it all, think, then dive deep one-at-a-time, still considering the whole but focusing on the tiny example in front of you. Try to figure out what's going on in people's minds as that example plays out, not what kind of meeting they're holding. If you can do that, then try to build together some things that seem to be going on no matter what the ritual or process. Incrementally more and more difficult and complex scenarios and see if those same invisible things continue to be important. 

Doing this, you don't end up with a generalized process. What you end up with is a constellation of categories of questions that seem to recur over and over again, something like "categories of things your mind is working on all the time no matter what process you use". That's a different thing entirely than what you would expect.

The implication here is quite interesting. A great many excellent processes involve a lot of meetings and such and might never actually outwardly do anything that looks like any of these general categories of questions. It's just that whatever else you're doing, activity in those categories also happens inside the minds of the people involved. 

In fact, as expected, most processes that involve analysis look nothing like these categories. Grooming/refinement is probably the exception, and the reason we covered it first. 

Even more interesting, my intuition says that it might actually be counterproductive to try to create processes directly around the categories, as most of the time in analysis a direct attack on something results in a lot of noise, paperwork, ritual, and well, no actual analysis. Analysis is weird in that direct attacks almost always result in suboptimal results. It's almost like your mind has to be looking away for it to work through what's in front of it.

This is not a book about process. If it were, boy would it be easier. I'd just give you the process. We'd have a bunch of little charts. And cycles. With the little stick men. This book is based on what happens inside a group of people's heads when they creatively make something that never existed before. How to get the the information they need.

After watching a lot of creative technical teams, it looks to me like there are five types of questions that arise during dialectics no matter what the context. All of these touch on tests and testing in some way. As far as I know, they all happen simultaneously inside of people's heads as the work progresses. Or maybe in a haphazard fashion in each person. Beats me. I gave up mind-reading after that problem I had in the circus.

So there is no loop. It's just a bunch of dots. I call it a wheel because wheels are cool. Interestingly, and this wasn't planned, it seems whatever dot you point at, dots "earlier" on the wheel have a direct impact. So whatever it is, it kind of turns. There are arcs. It is wheel-ish. Wheelie. Wheeling. Plus I like wheels. It's my book. When you write your book, you can have cyclones, or roller-coasters potato mashers or something else entirely. [^22:4]

[^22:4]: I advise against pyramids. Everybody does pyramids. Earthquakes and soup might be good if you could make it work. 

Earlier in the book we were on rock-solid footing with Plato and those old Greek dudes. As we move more and more into thinking-about-thinking, examining what may or may not be going on inside of people's heads, by necessity there's more guesswork happening. I'll show you what I have. I'll explain why I have it. I think it's useful, and I will show you how. Just be aware that this is speculative.

As I mentioned several times in section one, there is a proud tradition with philosophers of coming up with a few good ideas -- then taking the good ideas too far. I'm certainly no philosopher, but I'd like to do what I can to carry on the tradition. Later we'll be using the Big Old Analysis Wheel O' Pain to locate underground rivers and heal infirmities in the young.

Take it, try it. If you find this useful, then it's a win. I ask for nothing, except maybe a toga. If I could get a toga, that'd be great. Also maybe a marble statue that I can leave for future generations. But that's it. If you could make it a talking statue would be even better. Maybe with a hat.

## The Dots

Each dot represents a critical group of questions that keep occurring.

1. What's important right now?
2. How will we know we're changing things for the better?
3. Have we completed that change?
4. What's the simplest target system we can have that still does what we want?
5. What's the simplest way of looking at the problem that makes changing the target system the easiest?

## Moving Between the Dots.

If the dots are the general categories of questions people ask, looks like there are important process-type things happening where one dot connects to the other. This would lead to five different generic types of little conversations that advance analysis in one area.

1. Refinement: taking what's important and figuring out how we'll know we've done it
2. Development: taking the tests that define the positive change we want to make and making them pass 
3. Clean-up/Refactoring: Keeping all the tests passing while making the system simpler
4. Organizing/Restating: Taking what we've learned so far from engaging with the problem and re-thinking what the actual problem is 
5. Remembering/Compiling: Taking our understanding of the what the overall problem is and using that to determine what we have to do next 

Can you join dots across as well as in a circle? I don't know. That'd sure make the diagram more complicated, wouldn't it? It'd also probably use up our line budget.

## Scale Invariance

If these categories hold up, since they are about analysis in general, they would be *scale invariant*, that is, they would hold for doing tiny little jobs like TDD or giant, almost impossible jobs like organizing the family crazy Santa game each year.

## Question Arcs

One of the things that falls out of the diagram is the idea that if you are moving between two nodes, the node "prior" to those two sets up the context nicely for your movement. So if you're doing development, you're making failing tests pass. But you're doing that based on what's important or not -- which is the previous dot.

If you're doing Remembering/Compiling, you're taking your simplest understanding of what you're trying to do overall and come up with what the most important things are. But you do that based on your understanding how the target system is set up the way it is and why.

![](images/question-wheel.jpg)

We will continue to test out this categorization system for questions as we work through more and more complicated situations. But it's not a process. There is no cycle. It's not a wheel. Well it is a wheel, but it has no rim. You can't directly use it to go anywhere, only to evaluate other processes and your information flow to make sure you understand the types of things that happen to the model when questions pop up in any of these areas.

Just so we cover the Scrum stuff, here are the remaining rituals.

## Sprint Planning/"Ready for Work"

Sprint planning is simply taking goals/tests next up and figuring out what you can do, performing splits as necessary by using all the information you already have. Figure out what you can do, check the tests, code, and analysis model into source control with a label, then start doing it.

## Stand-up

Stand-ups are the way teams dynamically allocate their day. From an analysis standpoint, the information is there in the heads of the people in the room. It's much more about everybody as a group concentrating on value delivery instead each person doing some kind of weird status report.

Do you like points or hours or some kind tracking? Fine. Update the cards on the wall if you like. (You have a wall, right?) 

If you want to feed other systems, You can also just check the sprint backlog EasyAM file out, update a tag, and check it back in. You decide which tags work for you. If you have something like notepad and Dropbox, no tools required. Heck you could probably get it all working on Google Drive and have nice reports for zero overhead.

## Done/Demo 

A showcase is for the rest of the organization. After all, the team and Product Owner already knows what's working and what isn't. So while there's quite to add about the format I prefer, from the Analysis Model standpoint not a lot is going on.

Perhaps.

If you do a showcase and suddenly people from afar are giving you a boatload of feedback? Whoa horsey! You're in a dangerous spot here before those people think they're placing orders at McDonalds, not beginning some quality conversations. You'll need to focus that feedback and send it back into the team during Step 1 of grooming. The showcase is never an approval meeting. You've already got approval through the tests you had before you started. It's not a requirements session either. It's supposed to start synchronizing what the team is doing with the rest of the organization. In a way it's a bit like a stand-up, only at a higher level. And just like a stand-up, it should dynamically allocate time as needed for more grooming.

## Retrospectives Part 1

Let's come back to retrospectives when we dive deep into Meta in the next part.

## The Missing Meeting

Looking at the dots, and looking at what we've talked about so far, there's something missing.

Every kick-ass project I've ever been associated with had several instances where the team drastically re-imagined what the solution would look like and how they would deliver it. It always resulted in less work, more value, and happier customers. It's the last dot, "Look at all of it". So where's that in the processes we've been talking about?

I don't know if anything's  missing. I don't know if this has to be a meeting. I don't think so. But being able to rework and simplify what you're doing is a critical part of intellectually owning the problem. I wouldn't trust a team that didn't do it. Like all of the dots on the wheel of pain, it's important stuff that happens all the time while are thinking. Not a meeting.

I always worry about these kinds of questions and keep bringing them up until I see others start worrying about them too. Are we doing this the smart way? But most likely not a meeting. I'm thinking that "Do smart stuff" wouldn't look so good on the team calendar. Plus we'd all have to save all of our intelligent remarks for just that one meeting, since you don't use them early in the week and then run out.